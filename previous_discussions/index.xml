<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Previous_discussions | VLG</title>
    <link>https://vlgiitr.github.io/previous_discussions/</link>
      <atom:link href="https://vlgiitr.github.io/previous_discussions/index.xml" rel="self" type="application/rss+xml" />
    <description>Previous_discussions</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 08 Aug 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://vlgiitr.github.io/images/logo_hu0af03150d0ca39f3b12fa58639b44cf7_60645_300x300_fit_lanczos_2.png</url>
      <title>Previous_discussions</title>
      <link>https://vlgiitr.github.io/previous_discussions/</link>
    </image>
    
    <item>
      <title>Spring 2022 Discussions</title>
      <link>https://vlgiitr.github.io/previous_discussions/spring_2022_discussion/</link>
      <pubDate>Mon, 08 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/previous_discussions/spring_2022_discussion/</guid>
      <description>&lt;hr&gt;
&lt;p&gt;We conduct discussions every week where we dicuss  and recent advancements in the field of Deep Learning. Join our &lt;a href=&#34;https://discord.gg/AHCauPv8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Discord&lt;/a&gt; to attend the discussions!&lt;/p&gt;
&lt;!-- &lt;iframe src=&#34;https://discord.com/widget?id=877180035918884897&amp;theme=dark&#34; width=&#34;350&#34; height=&#34;500&#34; allowtransparency=&#34;true&#34; frameborder=&#34;0&#34; sandbox=&#34;allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts&#34;&gt;&lt;/iframe&gt; --&gt;
&lt;blockquote&gt;
&lt;p&gt;See the link below for all the resources&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;discussions&#34;&gt;Discussions&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;22-01-2022&lt;/td&gt;
&lt;td&gt;Neural Rendering&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;29-01-2022&lt;/td&gt;
&lt;td&gt;Multi-Model AI&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;05-02-2022&lt;/td&gt;
&lt;td&gt;Transformers&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;12-02-2022&lt;/td&gt;
&lt;td&gt;AlphaCode&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;19-02-2022&lt;/td&gt;
&lt;td&gt;Cross-breeding Transformers and CNNs&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;workshops&#34;&gt;Workshops&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Resources&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;19-03-2022&lt;/td&gt;
&lt;td&gt;Transfer Learning&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1-vGmphxTo4Zen2PBp6HSFPg-V9nP5w4i&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Colab Notebook&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;26-03-2022&lt;/td&gt;
&lt;td&gt;Introduction to RL&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1EhehhDzu5ak5uaC3H0xsRI6OR-Y6Yzzj?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Colab notebook&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;All the resources for this semester are compiled &lt;a href=&#34;https://cliff-tv-2e1.notion.site/VLG-Discussion-Resources-0a370b2c4aa34ba88580e8fcd0403de1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Autumn 2021 Discussions</title>
      <link>https://vlgiitr.github.io/previous_discussions/aut_2021_discussion/</link>
      <pubDate>Wed, 20 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/previous_discussions/aut_2021_discussion/</guid>
      <description>&lt;hr&gt;
&lt;p&gt;We conduct two discussions every week where we dicuss the basic concepts and recent advancements in the field of Deep Learning. Join our &lt;a href=&#34;https://teams.microsoft.com/l/team/19%3a0e691fdb81664f3b97d753311d437996%40thread.tacv2/conversations?groupId=34aceeff-a8f6-4efc-b650-4376d252c5f7&amp;amp;tenantId=38f62926-7559-4aef-84ae-cb5e172406fb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MS Team&lt;/a&gt; to attend the discussions!
Team Code : z1q54os&lt;/p&gt;
&lt;h3 id=&#34;basic-discussions&#34;&gt;Basic Discussions&lt;/h3&gt;
&lt;p&gt;We discuss a few fundamental concepts on Wednesdays.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Resources&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;18-08-2021&lt;/td&gt;
&lt;td&gt;Introduction to GANs&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1LqnIAr49wZHktXYtaiL3e1sk3Ar0P9nmEI_rg6MTXEg/edit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;25-08-2021&lt;/td&gt;
&lt;td&gt;VAE&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1HFygX3n7pjUJ35gVG-g7vP0dXiqevhtcGhT-SMtURX8/edit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;01-09-2021&lt;/td&gt;
&lt;td&gt;Sequence Modelling&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1DECew5g-z7jMBp-pwFmw_r87FdI3Ci7I/edit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;08-09-2021&lt;/td&gt;
&lt;td&gt;Transformers and Attention&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1p-A5TRKe2YJTkaA6O8wUMNlyHJDYsRrC8Suihuy-HWs/edit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;29-09-2021&lt;/td&gt;
&lt;td&gt;Reinforcement Learning&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1roMFcU5rfLrdB4RKndg7bENj6aYrTxBx/edit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;workshops&#34;&gt;Workshops&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Resources&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;13-10-2021&lt;/td&gt;
&lt;td&gt;Transfer Learning&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1rCrBIrynEqBBkr1SIkRXdsDB-jUVpZ52/edit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jupyter Notebook&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;20-10-2021&lt;/td&gt;
&lt;td&gt;VAE&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;&#34;&gt;Jupyter Notebook&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;advanced-discussions&#34;&gt;Advanced Discussions&lt;/h3&gt;
&lt;p&gt;We discuss the latest papers published in top tier conferences on Saturdays.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;div style=&#34;width:75px&#34;&gt;Date&lt;/div&gt;&lt;/th&gt;
&lt;th&gt;Paper 1&lt;/th&gt;
&lt;th&gt;&lt;div style=&#34;width:120px&#34;&gt;Link&lt;/div&gt;&lt;/th&gt;
&lt;th&gt;Paper 2&lt;/th&gt;
&lt;th&gt;&lt;div style=&#34;width:120px&#34;&gt;Link&lt;/div&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;18-08-2021&lt;/td&gt;
&lt;td&gt;Per-Pixel Classification is Not All You Need for Semantic Segmentation&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2107.06278&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Distilling the Knowledge in a Neural Network&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1503.02531&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;25-08-2021&lt;/td&gt;
&lt;td&gt;Large Scale Image Completion via Co-Modulated Generative Adversarial Networks&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.10428v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;09-11-2021&lt;/td&gt;
&lt;td&gt;Diverse Part Discovery: Occluded Person Re-Identification With Part-Aware Transformer&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Diverse_Part_Discovery_Occluded_Person_Re-Identification_With_Part-Aware_Transformer_CVPR_2021_paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;02-10-2021&lt;/td&gt;
&lt;td&gt;Towards Compact CNNs via Collaborative Compression&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Towards_Compact_CNNs_via_Collaborative_Compression_CVPR_2021_paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Is Space-Time Attention All You Need for Video Understanding?&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/2102.05095.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;09-10-2021&lt;/td&gt;
&lt;td&gt;Rethinking Attention with Performers&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/2009.14794.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Reformer: The Efficient Transformer&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/2001.04451.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;16-10-2021&lt;/td&gt;
&lt;td&gt;Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/1810.09536.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Spring 2021 Discussions</title>
      <link>https://vlgiitr.github.io/previous_discussions/spring_2021_discussion/</link>
      <pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/previous_discussions/spring_2021_discussion/</guid>
      <description>&lt;hr&gt;
&lt;p&gt;We conduct two discussions every week where we dicuss the basic concepts and recent advancements in the field of Deep Learning.&lt;/p&gt;
&lt;h3 id=&#34;basic-discussions&#34;&gt;Basic Discussions&lt;/h3&gt;
&lt;p&gt;We discuss a few fundamental concepts on Wednesdays.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Resources&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;14-04-2021&lt;/td&gt;
&lt;td&gt;Linear Algebra&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1rHrOqCQUuqUuKzB_BmXECXc0yC0IXJXdsym35gNJQlY/edit?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;21-04-2021&lt;/td&gt;
&lt;td&gt;Probability and Stats&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1l6DZk87_LxOqlfuDejCd2p7bkndRplDk/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;05-05-2021&lt;/td&gt;
&lt;td&gt;Neural Networks and CNNs&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1S1KvnC3avYr7I9PiI4FvC_aMg4TkLzON/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides-A&lt;/a&gt; &lt;a href=&#34;https://drive.google.com/file/d/1wXTUzBxQBwLQvrtZOudMDva_r1E_U8SG/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides B&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;advanced-discussions&#34;&gt;Advanced Discussions&lt;/h3&gt;
&lt;p&gt;We discuss the latest papers published in top tier conferences on Saturdays.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;div style=&#34;width:75px&#34;&gt;Date&lt;/div&gt;&lt;/th&gt;
&lt;th&gt;Paper 1&lt;/th&gt;
&lt;th&gt;&lt;div style=&#34;width:120px&#34;&gt;Link&lt;/div&gt;&lt;/th&gt;
&lt;th&gt;Paper 2&lt;/th&gt;
&lt;th&gt;&lt;div style=&#34;width:120px&#34;&gt;Link&lt;/div&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;20-02-2021&lt;/td&gt;
&lt;td&gt;GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2011.12100&#34;&gt;https://arxiv.org/abs/2011.12100&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Swapping Autoencoder for Deep Image Manipulation&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://taesung.me/SwappingAutoencoder/&#34;&gt;https://taesung.me/SwappingAutoencoder/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;27-02-2021&lt;/td&gt;
&lt;td&gt;ActionBytes: Learning from Trimmed Videos to Localize Actions&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2020/papers/Jain_ActionBytes_Learning_From_Trimmed_Videos_to_Localize_Actions_CVPR_2020_paper.pdf&#34;&gt;https://openaccess.thecvf.com/content_CVPR_2020/papers/Jain_ActionBytes_Learning_From_Trimmed_Videos_to_Localize_Actions_CVPR_2020_paper.pdf&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;The Importance of Modeling Data Missingness in Algorithmic Fairness: A Causal Perspective&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2012.11448&#34;&gt;https://arxiv.org/abs/2012.11448&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;13-03-2021&lt;/td&gt;
&lt;td&gt;Ultra-Data-Efficient GAN Training: Drawing A Lottery Ticket First, Then Training It Toughly&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.00397v1&#34;&gt;https://arxiv.org/abs/2103.00397v1&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.11929&#34;&gt;https://arxiv.org/abs/2010.11929&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;24-04-2021&lt;/td&gt;
&lt;td&gt;PREDICT &amp;amp; CLUSTER: Unsupervised Skeleton Based Action Recognition&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1911.12409&#34;&gt;https://arxiv.org/abs/1911.12409&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Dynamic Convolutions: Exploiting Spatial Sparsity for Faster Inference&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1912.03203&#34;&gt;https://arxiv.org/abs/1912.03203&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;01-05-2021&lt;/td&gt;
&lt;td&gt;SCOUT: Self-aware Discriminant Counterfactual Explanations&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_SCOUT_Self-Aware_Discriminant_Counterfactual_Explanations_CVPR_2020_paper.pdf&#34;&gt;https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_SCOUT_Self-Aware_Discriminant_Counterfactual_Explanations_CVPR_2020_paper.pdf&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;High-performance brain-to-text communication via imagined handwriting&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2020.07.01.183384v1.full.pdf&#34;&gt;https://www.biorxiv.org/content/10.1101/2020.07.01.183384v1.full.pdf&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Autumn 2020 Discussions</title>
      <link>https://vlgiitr.github.io/previous_discussions/aut_2020/</link>
      <pubDate>Sun, 29 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/previous_discussions/aut_2020/</guid>
      <description>&lt;hr&gt;
&lt;p&gt;We conduct two discussions every week where we dicuss the basic concepts and recent advancements in the field of Deep Learning.&lt;/p&gt;
&lt;h3 id=&#34;basic-discussions&#34;&gt;Basic Discussions&lt;/h3&gt;
&lt;p&gt;We discuss a few fundamental concepts on Wednesdays.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Resources&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;04-08-2020&lt;/td&gt;
&lt;td&gt;Linear Algebra&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1Wk6EPIQ7Cy7MUNKUpDPS5R-MrxbHm0zJ/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11-08-2020&lt;/td&gt;
&lt;td&gt;Probability&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1ZBubLdkpE_pb-mvy6fDltC3AcZeQsZRO/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;19-08-2020&lt;/td&gt;
&lt;td&gt;Neural Networks and CNNs&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1-0xcef-gOU590ucez6D9RlXtk1fyX9Eh/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;26-08-2020&lt;/td&gt;
&lt;td&gt;Basic CNN architectures&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1FybB6XIyqG1V1ezJwif70-2czRdY2PCw/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;02-09-2020&lt;/td&gt;
&lt;td&gt;RNNs&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/10nr5omq9ELJUP-NxIEU0ZOjqi7V2M_Jc/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;09-09-2020&lt;/td&gt;
&lt;td&gt;VAE&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/142-qoBEV3-rBO-FsFdxhRr420U6PzMfN/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;16-09-2020&lt;/td&gt;
&lt;td&gt;GANs&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1FNmDho1huVCQeG-iZcVyVpE6Z8UmhBbTqe0FYu2xf8o/edit?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;23-09-2020&lt;/td&gt;
&lt;td&gt;Embeddings&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1j8f4eKZteAs2gx30KHtTl-u1M2ASn8Hgjmbsph-naWI/edit?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;30-09-2020&lt;/td&gt;
&lt;td&gt;Attention and Transformer&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1JcKHknv3a33eDIJvO72MMfTqYIMJ0cyeJ2LeFtgapXU/edit?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;07-10-2020&lt;/td&gt;
&lt;td&gt;ELMo and BERT&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1cnIyEpPKKp91g5d6vkfzk_k2T07Du2PQ/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;14-10-2020&lt;/td&gt;
&lt;td&gt;RL-I: MDPs, Bellman Equations&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1neAp21D7DUCdnK--5DNaB5HWwSrzeKh7/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides-A&lt;/a&gt;  &lt;a href=&#34;https://drive.google.com/file/d/1HQhnvmZ5hPTxR1b2khlluJyVlqIx7Q16/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides-B&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11-11-2020&lt;/td&gt;
&lt;td&gt;Graph Neural Networks&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1CUCpubZElLWfnCi-JPE5mUXLgb-Bzyfo/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;advanced-discussions&#34;&gt;Advanced Discussions&lt;/h3&gt;
&lt;p&gt;We discuss the latest papers published in top tier conferences on Saturdays.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;div style=&#34;width:75px&#34;&gt;Date&lt;/div&gt;&lt;/th&gt;
&lt;th&gt;Paper 1&lt;/th&gt;
&lt;th&gt;&lt;div style=&#34;width:120px&#34;&gt;Link&lt;/div&gt;&lt;/th&gt;
&lt;th&gt;Paper 2&lt;/th&gt;
&lt;th&gt;&lt;div style=&#34;width:120px&#34;&gt;Link&lt;/div&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;01-08-2020&lt;/td&gt;
&lt;td&gt;Reinforced active  learning for image  segmentation&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2002.06583&#34;&gt;https://arxiv.org/abs/2002.06583&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Enhanced POET: Open-Ended Reinforcement  Learning through Unbounded Invention of  Learning Challenges and their Solutions&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2003.08536&#34;&gt;https://arxiv.org/abs/2003.08536&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;08-08-2020&lt;/td&gt;
&lt;td&gt;Towards Recognizing  Unseen Categories in  Unseen Domains&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2007.12256&#34;&gt;https://arxiv.org/abs/2007.12256&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Neural Arithmetic Units&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2001.05016&#34;&gt;https://arxiv.org/abs/2001.05016&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;29-08-2020&lt;/td&gt;
&lt;td&gt;Learning Memory  Access Patterns&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1803.02329&#34;&gt;https://arxiv.org/abs/1803.02329&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Equalization Loss for Long-Tailed  Object Recognition&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2003.05176&#34;&gt;https://arxiv.org/abs/2003.05176&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;05-09-2020&lt;/td&gt;
&lt;td&gt;PnPNet: End-to-End  Perception and Prediction  with Tracking in the Loop&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2005.14711&#34;&gt;https://arxiv.org/abs/2005.14711&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;CutMix: Regularization Strategy to Train  Strong Classifiers with Localizable  Features&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1905.048993&#34;&gt;https://arxiv.org/abs/1905.048993&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;26-09-2020&lt;/td&gt;
&lt;td&gt;Adversarial Continual  Learning&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2003.09553&#34;&gt;https://arxiv.org/abs/2003.09553&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Decentralized Reinforcement Learning:  Global Decision-Making via Local  Economic Transactions&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2007.02382&#34;&gt;https://arxiv.org/abs/2007.02382&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10-10-2020&lt;/td&gt;
&lt;td&gt;Implicit Latent Variable  Model for Scene-Consistent  Motion Forecasting&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2007.12036&#34;&gt;https://arxiv.org/abs/2007.12036&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Large Batch Optimization for Deep Learning:  Training BERT in 76 minutes&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1904.00962&#34;&gt;https://arxiv.org/abs/1904.00962&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;31-10-2020&lt;/td&gt;
&lt;td&gt;Causal Discovery with Reinforcement Learning&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1906.04477&#34;&gt;https://arxiv.org/abs/1906.04477&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;What Should Not Be Contrastive in Contrastive Learning&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2008.05659&#34;&gt;https://arxiv.org/abs/2008.05659&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;07-11-2020&lt;/td&gt;
&lt;td&gt;Dual Super-Resolution Learning for Semantic Segmentation&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Dual_Super-Resolution_Learning_for_Semantic_Segmentation_CVPR_2020_paper.pdf&#34;&gt;https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Dual_Super-Resolution_Learning_for_Semantic_Segmentation_CVPR_2020_paper.pdf&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Neural Architecture Search without Training Learning&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2006.04647&#34;&gt;https://arxiv.org/abs/2006.04647&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;28-11-2020&lt;/td&gt;
&lt;td&gt;Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1708.07120&#34;&gt;https://arxiv.org/abs/1708.07120&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://iclr.cc/virtual_2020/poster_r1xMH1BtvB.html&#34;&gt;https://iclr.cc/virtual_2020/poster_r1xMH1BtvB.html&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
  </channel>
</rss>
