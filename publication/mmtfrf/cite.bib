@inproceedings{10.1145/3394171.3413752,
author = {Sawhney, Ramit and Mathur, Puneet and Mangal, Ayush and Khanna, Piyush and Shah, Rajiv Ratn and Zimmermann, Roger},
title = {Multimodal Multi-Task Financial Risk Forecasting},
year = {2020},
isbn = {9781450379885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394171.3413752},
doi = {10.1145/3394171.3413752},
abstract = {Stock price movement and volatility prediction aim to predict stocks' future trends to help investors make sound investment decisions and model financial risk. Companies' earnings calls are a rich, underexplored source of multimodal information for financial forecasting. However, existing fintech solutions are not optimized towards harnessing the interplay between the multimodal verbal and vocal cues in earnings calls. In this work, we present a multi-task solution that utilizes domain specialized textual features and audio attentive alignment for predictive financial risk and price modeling. Our method advances existing solutions in two aspects: 1) tailoring a deep multimodal text-audio attention model, 2) optimizing volatility, and price movement prediction in a multi-task ensemble formulation. Through quantitative and qualitative analyses, we show the effectiveness of our deep multimodal approach.},
booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
pages = {456â€“465},
numpages = {10},
keywords = {finance, speech processing, stock prediction, multi-task learning},
location = {Seattle, WA, USA},
series = {MM '20}
}