<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>VLG</title>
    <link>https://vlgiitr.github.io/</link>
      <atom:link href="https://vlgiitr.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>VLG</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 01 Sep 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://vlgiitr.github.io/images/logo_hu0af03150d0ca39f3b12fa58639b44cf7_60645_300x300_fit_lanczos_3.png</url>
      <title>VLG</title>
      <link>https://vlgiitr.github.io/</link>
    </image>
    
    <item>
      <title></title>
      <link>https://vlgiitr.github.io/blogs/posts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/posts/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DL Discussions Fall Semeseter 2022</title>
      <link>https://vlgiitr.github.io/recents/workshop2021/</link>
      <pubDate>Thu, 01 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/workshop2021/</guid>
      <description>&lt;p&gt;DL Discusions by VLG for the Fall Semester 2022 start on 24th September. Stay Tuned&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Spring 2022 Discussions</title>
      <link>https://vlgiitr.github.io/previous_discussions/spring_2022_discussion/</link>
      <pubDate>Mon, 08 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/previous_discussions/spring_2022_discussion/</guid>
      <description>&lt;hr&gt;
&lt;p&gt;We conduct discussions every week where we dicuss  and recent advancements in the field of Deep Learning. Join our &lt;a href=&#34;https://discord.gg/AHCauPv8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Discord&lt;/a&gt; to attend the discussions!&lt;/p&gt;
&lt;!-- &lt;iframe src=&#34;https://discord.com/widget?id=877180035918884897&amp;theme=dark&#34; width=&#34;350&#34; height=&#34;500&#34; allowtransparency=&#34;true&#34; frameborder=&#34;0&#34; sandbox=&#34;allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts&#34;&gt;&lt;/iframe&gt; --&gt;
&lt;blockquote&gt;
&lt;p&gt;See the link below for all the resources&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;discussions&#34;&gt;Discussions&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;22-01-2022&lt;/td&gt;
&lt;td&gt;Neural Rendering&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;29-01-2022&lt;/td&gt;
&lt;td&gt;Multi-Model AI&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;05-02-2022&lt;/td&gt;
&lt;td&gt;Transformers&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;12-02-2022&lt;/td&gt;
&lt;td&gt;AlphaCode&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;19-02-2022&lt;/td&gt;
&lt;td&gt;Cross-breeding Transformers and CNNs&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;workshops&#34;&gt;Workshops&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Resources&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;19-03-2022&lt;/td&gt;
&lt;td&gt;Transfer Learning&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1-vGmphxTo4Zen2PBp6HSFPg-V9nP5w4i&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Colab Notebook&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;26-03-2022&lt;/td&gt;
&lt;td&gt;Introduction to RL&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1EhehhDzu5ak5uaC3H0xsRI6OR-Y6Yzzj?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Colab notebook&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;All the resources for this semester are compiled &lt;a href=&#34;https://cliff-tv-2e1.notion.site/VLG-Discussion-Resources-0a370b2c4aa34ba88580e8fcd0403de1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Weekly AI quiz on Instagram</title>
      <link>https://vlgiitr.github.io/recents/weekly_quiz/</link>
      <pubDate>Mon, 08 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/weekly_quiz/</guid>
      <description>&lt;p&gt;VLG now organises weekly quizes on out &lt;a href=&#34;https://www.instagram.com/vlgiitr/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Instagram&lt;/a&gt;. Hop in every Wednesday and flex your DL knowledge !&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Keys to Better Image Inpainting: Structure and Texture Go Hand in Hand</title>
      <link>https://vlgiitr.github.io/publication/imageimpainting/</link>
      <pubDate>Fri, 05 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/publication/imageimpainting/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DL Infographics on Instagram</title>
      <link>https://vlgiitr.github.io/recents/ai_bi_weekly_infographs/</link>
      <pubDate>Mon, 01 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/ai_bi_weekly_infographs/</guid>
      <description>&lt;p&gt;We are starting our forthnightly infographic series on &lt;a href=&#34;https://www.instagram.com/vlgiitr/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Instagram&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Members of VLG grab Gold Medal in Inter-IIT Tech Meet 10.0</title>
      <link>https://vlgiitr.github.io/recents/inter-iit/</link>
      <pubDate>Thu, 07 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/inter-iit/</guid>
      <description>&lt;p&gt;Members of VLG &lt;em&gt;Harsh Kumar&lt;/em&gt;, &amp;ldquo;&lt;em&gt;Kumar Devesh&lt;/em&gt;&amp;rdquo;, &amp;ldquo;&lt;em&gt;Sarthak Gupta&lt;/em&gt;&amp;rdquo;, participated in the High Prep Event - &amp;ldquo;Bosch model extraction attack for video classification&amp;rdquo; and grabbed GOLD Medal. Congratulations !!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Language Guided Meta-Control for Embodied Instruction Following</title>
      <link>https://vlgiitr.github.io/publication/metacontrolforembodiedinstructionfollowing/</link>
      <pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/publication/metacontrolforembodiedinstructionfollowing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Leveraging Dependency Grammar for Fine-Grained Offensive Language Detection using Graph Convolutional Networks</title>
      <link>https://vlgiitr.github.io/publication/levragingdependencygrammer/</link>
      <pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/publication/levragingdependencygrammer/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Password Cracking</title>
      <link>https://vlgiitr.github.io/blogs/password_cracking/</link>
      <pubDate>Mon, 30 May 2022 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/password_cracking/</guid>
      <description>&lt;p&gt;On hearing the term &amp;ldquo;password-cracking,&amp;rdquo; many will think this post will be about how to guess someone&amp;rsquo;s password or somewhat similar, but the reality is not always so satisfying.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On The Cross-Modal Transfer from Natural Language to Code through Adapter Modules</title>
      <link>https://vlgiitr.github.io/publication/crossmodeltransfenlp/</link>
      <pubDate>Sun, 01 May 2022 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/publication/crossmodeltransfenlp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>RelTransformer: A Transformer-Based Long-Tail Visual Relationship Recognition</title>
      <link>https://vlgiitr.github.io/publication/reitransformer/</link>
      <pubDate>Tue, 29 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/publication/reitransformer/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SeMask: Semantically Masked Transformers for Semantic Segmentation</title>
      <link>https://vlgiitr.github.io/publication/semask/</link>
      <pubDate>Thu, 23 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/publication/semask/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Autumn 2021 Discussions</title>
      <link>https://vlgiitr.github.io/previous_discussions/aut_2021_discussion/</link>
      <pubDate>Wed, 20 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/previous_discussions/aut_2021_discussion/</guid>
      <description>&lt;hr&gt;
&lt;p&gt;We conduct two discussions every week where we dicuss the basic concepts and recent advancements in the field of Deep Learning. Join our &lt;a href=&#34;https://teams.microsoft.com/l/team/19%3a0e691fdb81664f3b97d753311d437996%40thread.tacv2/conversations?groupId=34aceeff-a8f6-4efc-b650-4376d252c5f7&amp;amp;tenantId=38f62926-7559-4aef-84ae-cb5e172406fb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MS Team&lt;/a&gt; to attend the discussions!
Team Code : z1q54os&lt;/p&gt;
&lt;h3 id=&#34;basic-discussions&#34;&gt;Basic Discussions&lt;/h3&gt;
&lt;p&gt;We discuss a few fundamental concepts on Wednesdays.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Resources&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;18-08-2021&lt;/td&gt;
&lt;td&gt;Introduction to GANs&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1LqnIAr49wZHktXYtaiL3e1sk3Ar0P9nmEI_rg6MTXEg/edit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;25-08-2021&lt;/td&gt;
&lt;td&gt;VAE&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1HFygX3n7pjUJ35gVG-g7vP0dXiqevhtcGhT-SMtURX8/edit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;01-09-2021&lt;/td&gt;
&lt;td&gt;Sequence Modelling&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1DECew5g-z7jMBp-pwFmw_r87FdI3Ci7I/edit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;08-09-2021&lt;/td&gt;
&lt;td&gt;Transformers and Attention&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1p-A5TRKe2YJTkaA6O8wUMNlyHJDYsRrC8Suihuy-HWs/edit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;29-09-2021&lt;/td&gt;
&lt;td&gt;Reinforcement Learning&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1roMFcU5rfLrdB4RKndg7bENj6aYrTxBx/edit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;workshops&#34;&gt;Workshops&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Resources&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;13-10-2021&lt;/td&gt;
&lt;td&gt;Transfer Learning&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1rCrBIrynEqBBkr1SIkRXdsDB-jUVpZ52/edit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jupyter Notebook&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;20-10-2021&lt;/td&gt;
&lt;td&gt;VAE&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;&#34;&gt;Jupyter Notebook&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;advanced-discussions&#34;&gt;Advanced Discussions&lt;/h3&gt;
&lt;p&gt;We discuss the latest papers published in top tier conferences on Saturdays.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;div style=&#34;width:75px&#34;&gt;Date&lt;/div&gt;&lt;/th&gt;
&lt;th&gt;Paper 1&lt;/th&gt;
&lt;th&gt;&lt;div style=&#34;width:120px&#34;&gt;Link&lt;/div&gt;&lt;/th&gt;
&lt;th&gt;Paper 2&lt;/th&gt;
&lt;th&gt;&lt;div style=&#34;width:120px&#34;&gt;Link&lt;/div&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;18-08-2021&lt;/td&gt;
&lt;td&gt;Per-Pixel Classification is Not All You Need for Semantic Segmentation&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2107.06278&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Distilling the Knowledge in a Neural Network&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1503.02531&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;25-08-2021&lt;/td&gt;
&lt;td&gt;Large Scale Image Completion via Co-Modulated Generative Adversarial Networks&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.10428v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;09-11-2021&lt;/td&gt;
&lt;td&gt;Diverse Part Discovery: Occluded Person Re-Identification With Part-Aware Transformer&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Diverse_Part_Discovery_Occluded_Person_Re-Identification_With_Part-Aware_Transformer_CVPR_2021_paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;02-10-2021&lt;/td&gt;
&lt;td&gt;Towards Compact CNNs via Collaborative Compression&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Towards_Compact_CNNs_via_Collaborative_Compression_CVPR_2021_paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Is Space-Time Attention All You Need for Video Understanding?&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/2102.05095.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;09-10-2021&lt;/td&gt;
&lt;td&gt;Rethinking Attention with Performers&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/2009.14794.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Reformer: The Efficient Transformer&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/2001.04451.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;16-10-2021&lt;/td&gt;
&lt;td&gt;Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/1810.09536.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Exploring Long tail Visual Relationship Recognition with Large Vocabulary</title>
      <link>https://vlgiitr.github.io/publication/longtailvisualrelationshipwithlargevocab/</link>
      <pubDate>Sat, 25 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/publication/longtailvisualrelationshipwithlargevocab/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Spring 2021 Discussions</title>
      <link>https://vlgiitr.github.io/previous_discussions/spring_2021_discussion/</link>
      <pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/previous_discussions/spring_2021_discussion/</guid>
      <description>&lt;hr&gt;
&lt;p&gt;We conduct two discussions every week where we dicuss the basic concepts and recent advancements in the field of Deep Learning.&lt;/p&gt;
&lt;h3 id=&#34;basic-discussions&#34;&gt;Basic Discussions&lt;/h3&gt;
&lt;p&gt;We discuss a few fundamental concepts on Wednesdays.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Resources&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;14-04-2021&lt;/td&gt;
&lt;td&gt;Linear Algebra&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1rHrOqCQUuqUuKzB_BmXECXc0yC0IXJXdsym35gNJQlY/edit?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;21-04-2021&lt;/td&gt;
&lt;td&gt;Probability and Stats&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1l6DZk87_LxOqlfuDejCd2p7bkndRplDk/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;05-05-2021&lt;/td&gt;
&lt;td&gt;Neural Networks and CNNs&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1S1KvnC3avYr7I9PiI4FvC_aMg4TkLzON/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides-A&lt;/a&gt; &lt;a href=&#34;https://drive.google.com/file/d/1wXTUzBxQBwLQvrtZOudMDva_r1E_U8SG/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides B&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;advanced-discussions&#34;&gt;Advanced Discussions&lt;/h3&gt;
&lt;p&gt;We discuss the latest papers published in top tier conferences on Saturdays.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;div style=&#34;width:75px&#34;&gt;Date&lt;/div&gt;&lt;/th&gt;
&lt;th&gt;Paper 1&lt;/th&gt;
&lt;th&gt;&lt;div style=&#34;width:120px&#34;&gt;Link&lt;/div&gt;&lt;/th&gt;
&lt;th&gt;Paper 2&lt;/th&gt;
&lt;th&gt;&lt;div style=&#34;width:120px&#34;&gt;Link&lt;/div&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;20-02-2021&lt;/td&gt;
&lt;td&gt;GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2011.12100&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2011.12100&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Swapping Autoencoder for Deep Image Manipulation&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://taesung.me/SwappingAutoencoder/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://taesung.me/SwappingAutoencoder/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;27-02-2021&lt;/td&gt;
&lt;td&gt;ActionBytes: Learning from Trimmed Videos to Localize Actions&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2020/papers/Jain_ActionBytes_Learning_From_Trimmed_Videos_to_Localize_Actions_CVPR_2020_paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://openaccess.thecvf.com/content_CVPR_2020/papers/Jain_ActionBytes_Learning_From_Trimmed_Videos_to_Localize_Actions_CVPR_2020_paper.pdf&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;The Importance of Modeling Data Missingness in Algorithmic Fairness: A Causal Perspective&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2012.11448&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2012.11448&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;13-03-2021&lt;/td&gt;
&lt;td&gt;Ultra-Data-Efficient GAN Training: Drawing A Lottery Ticket First, Then Training It Toughly&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.00397v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2103.00397v1&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.11929&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2010.11929&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;24-04-2021&lt;/td&gt;
&lt;td&gt;PREDICT &amp;amp; CLUSTER: Unsupervised Skeleton Based Action Recognition&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1911.12409&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/1911.12409&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Dynamic Convolutions: Exploiting Spatial Sparsity for Faster Inference&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1912.03203&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/1912.03203&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;01-05-2021&lt;/td&gt;
&lt;td&gt;SCOUT: Self-aware Discriminant Counterfactual Explanations&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_SCOUT_Self-Aware_Discriminant_Counterfactual_Explanations_CVPR_2020_paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_SCOUT_Self-Aware_Discriminant_Counterfactual_Explanations_CVPR_2020_paper.pdf&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;High-performance brain-to-text communication via imagined handwriting&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2020.07.01.183384v1.full.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.biorxiv.org/content/10.1101/2020.07.01.183384v1.full.pdf&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>New Blog on Learnings during research published on Medium!</title>
      <link>https://vlgiitr.github.io/recents/noisy_research_blog/</link>
      <pubDate>Wed, 28 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/noisy_research_blog/</guid>
      <description>&lt;p&gt;The new blog on the topic &lt;strong&gt;Riding the Noisy Research Track&lt;/strong&gt; by &lt;em&gt;Jitesh Jain&lt;/em&gt; is now published on Medium. In this blog, one of our members shares his experience and learnings in research, and covers some essential guidelines for a beginner in this field. Do give the blog a read &lt;a href=&#34;https://medium.com/vlgiitr/riding-the-noisy-research-track-4035e64e7ea8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Riding the Noisy Research Track</title>
      <link>https://vlgiitr.github.io/blogs/noisy_research_track/</link>
      <pubDate>Wed, 28 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/noisy_research_track/</guid>
      <description>&lt;p&gt;It&amp;rsquo;s pretty common to get fascinated by the idea of research. But sometimes we lose intrest midway through it. Ride this noisy track with one of our undergrad reasercher !&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New Blog on Researching as an Undergrad Published on Medium!</title>
      <link>https://vlgiitr.github.io/recents/research_deku_blog/</link>
      <pubDate>Fri, 23 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/research_deku_blog/</guid>
      <description>&lt;p&gt;The new blog on the topic &lt;strong&gt;What doing research as an undergrad can teach you.&lt;/strong&gt; by &lt;em&gt;Ayush Mangal&lt;/em&gt; is now published on Medium. The Blog talks about the writer&amp;rsquo;s experience as a undergrad researcher with the hope that this article might motivate more people to give research a shot even if they don’t want to become a scientist and remove the stigma surrounding research from their mind. Do give the blog a read &lt;a href=&#34;https://medium.com/vlgiitr/what-doing-research-as-an-undergrad-can-teach-you-fa6ea1836b97&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What doing research as an undergrad can teach you.</title>
      <link>https://vlgiitr.github.io/blogs/research_deku/</link>
      <pubDate>Wed, 23 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/research_deku/</guid>
      <description>&lt;p&gt;What is research but a blind date with knowledge ? Explore more about researching as an undergrad with our senpai deku!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New Blog on Optimizers Published on Medium!</title>
      <link>https://vlgiitr.github.io/recents/optimizer_blog/</link>
      <pubDate>Thu, 17 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/optimizer_blog/</guid>
      <description>&lt;p&gt;The new blog on the topic &lt;strong&gt;Optimizer: diving deep into Neural Networks&lt;/strong&gt; by &lt;em&gt;Rohan Garg&lt;/em&gt; is now published on Medium. The Blog covers the basics of the topic and the mathematical fundamentals followed in subject matter. Do give the blog a read &lt;a href=&#34;https://medium.com/vlgiitr/optimizer-diving-into-deep-neural-networks-94a6ee28f7c5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Optimizer: diving deep into Neural Networks</title>
      <link>https://vlgiitr.github.io/blogs/optimizer/</link>
      <pubDate>Thu, 17 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/optimizer/</guid>
      <description>&lt;p&gt;Waiting for the neural network to train is always annoying, make sure you use the right optimizers !&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Autumn 2020 Discussions</title>
      <link>https://vlgiitr.github.io/previous_discussions/aut_2020/</link>
      <pubDate>Sun, 29 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/previous_discussions/aut_2020/</guid>
      <description>&lt;hr&gt;
&lt;p&gt;We conduct two discussions every week where we dicuss the basic concepts and recent advancements in the field of Deep Learning.&lt;/p&gt;
&lt;h3 id=&#34;basic-discussions&#34;&gt;Basic Discussions&lt;/h3&gt;
&lt;p&gt;We discuss a few fundamental concepts on Wednesdays.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Resources&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;04-08-2020&lt;/td&gt;
&lt;td&gt;Linear Algebra&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1Wk6EPIQ7Cy7MUNKUpDPS5R-MrxbHm0zJ/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11-08-2020&lt;/td&gt;
&lt;td&gt;Probability&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1ZBubLdkpE_pb-mvy6fDltC3AcZeQsZRO/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;19-08-2020&lt;/td&gt;
&lt;td&gt;Neural Networks and CNNs&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1-0xcef-gOU590ucez6D9RlXtk1fyX9Eh/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;26-08-2020&lt;/td&gt;
&lt;td&gt;Basic CNN architectures&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1FybB6XIyqG1V1ezJwif70-2czRdY2PCw/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;02-09-2020&lt;/td&gt;
&lt;td&gt;RNNs&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/10nr5omq9ELJUP-NxIEU0ZOjqi7V2M_Jc/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;09-09-2020&lt;/td&gt;
&lt;td&gt;VAE&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/142-qoBEV3-rBO-FsFdxhRr420U6PzMfN/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;16-09-2020&lt;/td&gt;
&lt;td&gt;GANs&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1FNmDho1huVCQeG-iZcVyVpE6Z8UmhBbTqe0FYu2xf8o/edit?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;23-09-2020&lt;/td&gt;
&lt;td&gt;Embeddings&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1j8f4eKZteAs2gx30KHtTl-u1M2ASn8Hgjmbsph-naWI/edit?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;30-09-2020&lt;/td&gt;
&lt;td&gt;Attention and Transformer&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/1JcKHknv3a33eDIJvO72MMfTqYIMJ0cyeJ2LeFtgapXU/edit?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;07-10-2020&lt;/td&gt;
&lt;td&gt;ELMo and BERT&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1cnIyEpPKKp91g5d6vkfzk_k2T07Du2PQ/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;14-10-2020&lt;/td&gt;
&lt;td&gt;RL-I: MDPs, Bellman Equations&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1neAp21D7DUCdnK--5DNaB5HWwSrzeKh7/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides-A&lt;/a&gt;  &lt;a href=&#34;https://drive.google.com/file/d/1HQhnvmZ5hPTxR1b2khlluJyVlqIx7Q16/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides-B&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11-11-2020&lt;/td&gt;
&lt;td&gt;Graph Neural Networks&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://drive.google.com/file/d/1CUCpubZElLWfnCi-JPE5mUXLgb-Bzyfo/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;advanced-discussions&#34;&gt;Advanced Discussions&lt;/h3&gt;
&lt;p&gt;We discuss the latest papers published in top tier conferences on Saturdays.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;div style=&#34;width:75px&#34;&gt;Date&lt;/div&gt;&lt;/th&gt;
&lt;th&gt;Paper 1&lt;/th&gt;
&lt;th&gt;&lt;div style=&#34;width:120px&#34;&gt;Link&lt;/div&gt;&lt;/th&gt;
&lt;th&gt;Paper 2&lt;/th&gt;
&lt;th&gt;&lt;div style=&#34;width:120px&#34;&gt;Link&lt;/div&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;01-08-2020&lt;/td&gt;
&lt;td&gt;Reinforced active  learning for image  segmentation&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2002.06583&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2002.06583&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Enhanced POET: Open-Ended Reinforcement  Learning through Unbounded Invention of  Learning Challenges and their Solutions&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2003.08536&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2003.08536&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;08-08-2020&lt;/td&gt;
&lt;td&gt;Towards Recognizing  Unseen Categories in  Unseen Domains&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2007.12256&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2007.12256&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Neural Arithmetic Units&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2001.05016&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2001.05016&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;29-08-2020&lt;/td&gt;
&lt;td&gt;Learning Memory  Access Patterns&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1803.02329&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/1803.02329&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Equalization Loss for Long-Tailed  Object Recognition&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2003.05176&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2003.05176&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;05-09-2020&lt;/td&gt;
&lt;td&gt;PnPNet: End-to-End  Perception and Prediction  with Tracking in the Loop&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2005.14711&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2005.14711&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;CutMix: Regularization Strategy to Train  Strong Classifiers with Localizable  Features&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1905.048993&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/1905.048993&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;26-09-2020&lt;/td&gt;
&lt;td&gt;Adversarial Continual  Learning&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2003.09553&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2003.09553&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Decentralized Reinforcement Learning:  Global Decision-Making via Local  Economic Transactions&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2007.02382&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2007.02382&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10-10-2020&lt;/td&gt;
&lt;td&gt;Implicit Latent Variable  Model for Scene-Consistent  Motion Forecasting&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2007.12036&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2007.12036&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Large Batch Optimization for Deep Learning:  Training BERT in 76 minutes&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1904.00962&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/1904.00962&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;31-10-2020&lt;/td&gt;
&lt;td&gt;Causal Discovery with Reinforcement Learning&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1906.04477&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/1906.04477&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;What Should Not Be Contrastive in Contrastive Learning&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2008.05659&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2008.05659&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;07-11-2020&lt;/td&gt;
&lt;td&gt;Dual Super-Resolution Learning for Semantic Segmentation&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Dual_Super-Resolution_Learning_for_Semantic_Segmentation_CVPR_2020_paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Dual_Super-Resolution_Learning_for_Semantic_Segmentation_CVPR_2020_paper.pdf&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Neural Architecture Search without Training Learning&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2006.04647&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2006.04647&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;28-11-2020&lt;/td&gt;
&lt;td&gt;Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/1708.07120&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/1708.07120&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://iclr.cc/virtual_2020/poster_r1xMH1BtvB.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://iclr.cc/virtual_2020/poster_r1xMH1BtvB.html&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Multimodal Multi-Task Financial Risk Forecasting</title>
      <link>https://vlgiitr.github.io/publication/mmtfrf/</link>
      <pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/publication/mmtfrf/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Metric Learning: It’s all about the Distance (Medium)</title>
      <link>https://vlgiitr.github.io/blogs/metric_learning/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/metric_learning/</guid>
      <description>&lt;p&gt;Going deeper and deeper works, but only when we know what exactly to learn. Let’s make sure we learn the right thing.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New Blog on Metric Learning Published on Medium!</title>
      <link>https://vlgiitr.github.io/recents/metric_blog/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/metric_blog/</guid>
      <description>&lt;p&gt;The new blog on the topic &lt;strong&gt;Metric Learning: It’s all about the Distance&lt;/strong&gt; by &lt;em&gt;Keerat Kaur Guliani&lt;/em&gt; is now published on Medium. The Blog covers the basics of the topic and the common notations followed in subject matter and some of the recent work in this field. Along with this, the blog is supplemented with animations using Manim Engine to further bring forward the main crux of the subject. Do give the blog a read &lt;a href=&#34;https://medium.com/vlgiitr/metric-learning-its-all-about-the-distance-143a199ab7a5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DEAP Cache: Deep Eviction Admission and Prefetching for Cache</title>
      <link>https://vlgiitr.github.io/publication/deap/</link>
      <pubDate>Sat, 19 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/publication/deap/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Deep Cache Replacement</title>
      <link>https://vlgiitr.github.io/project/deap/</link>
      <pubDate>Sat, 19 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/project/deap/</guid>
      <description>&lt;p&gt;The PyTorch codebase for DEAP Cache: Deep Eviction Admission and Prefetching for Cache.&lt;/p&gt;
&lt;p&gt;In this paper, we propose a DL based approach to tackle the problem of Cache Replacement. This is the first time an approach has tried learning all the three policies: Admission, Prefetching and Eviction. Unlike, previous methods which relied on past statistics for carrying out cache replacement, we predict future statistics (frequency and recency) and then use an online RL-algorithm for eviction.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Preprint out for the paper: DEAP Cache: Deep Eviction Admission and Prefetching for Cache!</title>
      <link>https://vlgiitr.github.io/recents/deap/</link>
      <pubDate>Sat, 19 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/deap/</guid>
      <description>&lt;p&gt;In this paper, we propose a DL based approach to tackle the problem of Cache Replacement. This is the first time an approach has tried learning all the three policies: Admission, Prefetching and Eviction. Unlike, previous methods which relied on past statistics for carrying out cache replacement, we predict future statistics (frequency and recency) and then use an online RL-algorithm for eviction.&lt;/p&gt;
&lt;p&gt;Checkout the preprint &lt;a href=&#34;https://arxiv.org/abs/2009.09206&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Less Wrong COVID-19 Projections With Interactive Assumptions</title>
      <link>https://vlgiitr.github.io/publication/covision/</link>
      <pubDate>Mon, 14 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/publication/covision/</guid>
      <description></description>
    </item>
    
    <item>
      <title>VacSIM: Learning Effective Strategies for COVID-19 Vaccine Distribution using Reinforcement Learning</title>
      <link>https://vlgiitr.github.io/publication/vacsim/</link>
      <pubDate>Mon, 14 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/publication/vacsim/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DL Topics</title>
      <link>https://vlgiitr.github.io/project/dl_topics/</link>
      <pubDate>Sun, 13 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/project/dl_topics/</guid>
      <description>&lt;p&gt;This repo contains a list of topics which we feel that one should be comfortable with before appearing for a DL interview. This list is by no means exhaustive (as the field is very wide and ever growing).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Basic and Advanced Discussions for the Autumn Semester (2020-21) restart!</title>
      <link>https://vlgiitr.github.io/recents/disc/</link>
      <pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/disc/</guid>
      <description>&lt;p&gt;The Basic and Advanced for the new semester begins. We have some really exciting topics lined up to be discussed. With the current pandemic, all the discussions will be online. Just as always, two discussions(Basic and Advanced) will be held every week. We are looking forward to new faces joining in the open discussions. You can also view the discussion schedule and other resources &lt;a href=&#34;https://vlgiitr.github.io/discussions/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Talk with Alumni: A Talk with Shagun Sodhani</title>
      <link>https://vlgiitr.github.io/recents/talk_shagun/</link>
      <pubDate>Sun, 26 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/talk_shagun/</guid>
      <description>&lt;p&gt;The core members of the group had a very informative talk and discussion with our alumnus, Shagun Sodhani (&lt;a href=&#34;https://shagunsodhani.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Profile&lt;/a&gt;). He is currently a research engineer at FAIR and was one of the co-founders of ACM, IIT Roorkee Chapter. He shared experiences of his undergrad years, and also some of the crucial advice to our current members.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Papers We Read</title>
      <link>https://vlgiitr.github.io/project/papers_we_read/</link>
      <pubDate>Wed, 08 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/project/papers_we_read/</guid>
      <description>&lt;p&gt;The repo contains summaries of various papers we discuss in our regular discussions and also some other recent papers which we feel have some really exciting contributions for the field.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New Blog on Curse of Dimensionality Published on Medium!</title>
      <link>https://vlgiitr.github.io/recents/curse_blog/</link>
      <pubDate>Thu, 11 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/curse_blog/</guid>
      <description>&lt;p&gt;The new blog on the topic &lt;strong&gt;The Curse of Dimensionality&lt;/strong&gt; by &lt;em&gt;Jitesh Jain&lt;/em&gt; is now published on Medium. The Blog covers the basics of the topic and the mathematical fundamentals followed in subject matter. Along with this, the blog is supplemented with animations using Manim Engine to further bring forward the main crux of the subject. Do give the blog a read &lt;a href=&#34;https://medium.com/vlgiitr/the-curse-of-dimensionality-15f950e519d2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Curse of Dimensionality  (Medium)</title>
      <link>https://vlgiitr.github.io/blogs/the-curse-of-dimensionality/</link>
      <pubDate>Thu, 11 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/the-curse-of-dimensionality/</guid>
      <description>&lt;p&gt;Some say breaking this curse is as herculian of a task as breaking the Curse of Medusa. Well, who are we to judge…&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New Blog on Principal Component Analysis on Medium!</title>
      <link>https://vlgiitr.github.io/recents/pca_blog/</link>
      <pubDate>Wed, 03 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/pca_blog/</guid>
      <description>&lt;p&gt;The new blog on the topic &lt;strong&gt;Principal Component Analysis&lt;/strong&gt; by &lt;em&gt;Ankit Biswas&lt;/em&gt; is now published on Medium. The Blog covers the basics of the topic and the mathematical fundamentals followed in subject matter. Along with this, the blog is supplemented with animations using Manim Engine to further bring forward the main crux of the subject. Do give the blog a read &lt;a href=&#34;https://medium.com/vlgiitr/principal-components-analysis-82a7682323e6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Principal Component Analysis (Medium)</title>
      <link>https://vlgiitr.github.io/blogs/pca/</link>
      <pubDate>Wed, 03 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/pca/</guid>
      <description>&lt;p&gt;Too many dimensions can be bad for your model’s health. Here comes PCA to the rescue.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New Blog on Singular Value Decomposition on Medium!</title>
      <link>https://vlgiitr.github.io/recents/svd_blog/</link>
      <pubDate>Tue, 26 May 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/svd_blog/</guid>
      <description>&lt;p&gt;The new blog on the topic &lt;strong&gt;Singular Value Decomposition&lt;/strong&gt; by &lt;em&gt;Kaaira Gupta&lt;/em&gt; is now published on Medium. The Blog covers the basics of the topic and the mathematical fundamentals followed in subject matter. Along with this, the blog is supplemented with animations using Manim Engine to further bring forward the main crux of the subject. Do give the blog a read &lt;a href=&#34;https://medium.com/vlgiitr/eli5-singular-value-decomposition-svd-955c151f9907&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Singular Value Decomposition (Medium)</title>
      <link>https://vlgiitr.github.io/blogs/svd/</link>
      <pubDate>Tue, 26 May 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/svd/</guid>
      <description>&lt;p&gt;Whether you want to compress an image or calculate pseudo-inverse, SVD will always be there for you.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Preprint out for the paper: Universal Adversarial Perturbations: A Survey!</title>
      <link>https://vlgiitr.github.io/recents/uap/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/uap/</guid>
      <description>&lt;p&gt;The new survey paper on the topic of Universal Adversarial Perturbations is out now on arxiv. The paper covers the basic terminologies and concepts that build up the subject matter of Adversarial Perturbations and then all the recent literature work to further develop the field. Lastly it also delves into the applications of the same and the future work directions possible in this field.&lt;/p&gt;
&lt;p&gt;Checkout the preprint &lt;a href=&#34;https://arxiv.org/abs/2005.08087&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Preprint out for the paper: Visual Relationship Detection using Scene Graphs: A Survey!</title>
      <link>https://vlgiitr.github.io/recents/scene_graph/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/scene_graph/</guid>
      <description>&lt;p&gt;The new survey paper on the topic of Scene Graphs is out now on arxiv. The paper covers the basic terminologies and concepts that build up the subject matter of Scene Graphs and then all the recent literature work to further develop the field. Lastly it also delves into the applications of the same and the future work directions possible in this field.&lt;/p&gt;
&lt;p&gt;Checkout the preprint &lt;a href=&#34;https://arxiv.org/abs/2005.08045&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Universal Adversarial Perturbations: A Survey</title>
      <link>https://vlgiitr.github.io/publication/uap/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/publication/uap/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Visual Relationship Detection using Scene Graphs: A Survey</title>
      <link>https://vlgiitr.github.io/publication/scene_graph/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/publication/scene_graph/</guid>
      <description></description>
    </item>
    
    <item>
      <title>New Blog on Support Vector Machines on Medium!</title>
      <link>https://vlgiitr.github.io/recents/svm_blog/</link>
      <pubDate>Fri, 15 May 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/svm_blog/</guid>
      <description>&lt;p&gt;The new blog on the topic &lt;strong&gt;Support Vector Machines&lt;/strong&gt; by &lt;em&gt;Aaryan Garg&lt;/em&gt; is now published on Medium. The Blog covers the basics of the topic and the mathematical fundamentals followed in subject matter. Along with this, the blog is supplemented with animations using Manim Engine to further bring forward the main crux of the subject. Do give the blog a read &lt;a href=&#34;https://medium.com/vlgiitr/support-vector-machines-77babd8545bb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Support Vector Machine  (Medium)</title>
      <link>https://vlgiitr.github.io/blogs/svm/</link>
      <pubDate>Fri, 15 May 2020 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/svm/</guid>
      <description>&lt;p&gt;SVM is the Mr. Perfect of Machine Learning Classifiers. It basically wants different examples to be as far as possible.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Revisiting CycleGAN for Semi-Supervised Segmentation</title>
      <link>https://vlgiitr.github.io/publication/cycle-gan/</link>
      <pubDate>Sun, 03 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/publication/cycle-gan/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Generative Adversarial Network based Ensemble Technique for Automatic Evaluation of Machine Synthesized Speech</title>
      <link>https://vlgiitr.github.io/publication/gan-ensemble/</link>
      <pubDate>Sat, 02 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/publication/gan-ensemble/</guid>
      <description></description>
    </item>
    
    <item>
      <title>GenZoo</title>
      <link>https://vlgiitr.github.io/project/genzoo/</link>
      <pubDate>Sun, 20 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/project/genzoo/</guid>
      <description>&lt;p&gt;GenZoo is a repository that provides implementations of generative models in various frameworks, namely Tensorflow and Pytorch. This was a project taken up by VLG-IITR for the summers of 2019, done with the collaborative efforts of various students.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GAN-Tree: An Incrementally Learned Hierarchical Generative Framework for Multi-Modal Data Distributions</title>
      <link>https://vlgiitr.github.io/publication/gan-tree/</link>
      <pubDate>Tue, 02 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/publication/gan-tree/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Advanced Problems (Medium)</title>
      <link>https://vlgiitr.github.io/blogs/advanced_problems/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/advanced_problems/</guid>
      <description>&lt;p&gt;A few problems for the ones looking to test their learning.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dropout</title>
      <link>https://vlgiitr.github.io/blogs/dropout/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/dropout/</guid>
      <description>&lt;p&gt;Notes on the regularization method Dropout.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Guide to Deep Learning (Medium)</title>
      <link>https://vlgiitr.github.io/blogs/dl-guide/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/dl-guide/</guid>
      <description>&lt;p&gt;This blog contains a guide to get started with Deep Learning as well as get in-depth knowledge of the field.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>InceptionNet</title>
      <link>https://vlgiitr.github.io/blogs/inception/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/inception/</guid>
      <description>&lt;p&gt;Notes on the the InceptionNet CNN architecture.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linear Algebra</title>
      <link>https://vlgiitr.github.io/blogs/linalg/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/linalg/</guid>
      <description>&lt;p&gt;Notes on Linear Algebra from the DL Book.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Net2Net</title>
      <link>https://vlgiitr.github.io/blogs/net2net/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/net2net/</guid>
      <description>&lt;p&gt;Notes on the Net2Net architecture.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Probability and Information Theory</title>
      <link>https://vlgiitr.github.io/blogs/probstats/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/probstats/</guid>
      <description>&lt;p&gt;Notes on Probability and Information Theory from the DL Book.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RCNN</title>
      <link>https://vlgiitr.github.io/blogs/rcnn/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/rcnn/</guid>
      <description>&lt;p&gt;Notes on the object detection architecture RCNN.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ResNet</title>
      <link>https://vlgiitr.github.io/blogs/resnet/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/resnet/</guid>
      <description>&lt;p&gt;Notes on the CNN Architecture ResNet.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>VGGNet</title>
      <link>https://vlgiitr.github.io/blogs/vgg/</link>
      <pubDate>Fri, 17 May 2019 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/blogs/vgg/</guid>
      <description>&lt;p&gt;Notes on the CNN Architecture VGGNet.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Group-Level-Emotion-Recognition</title>
      <link>https://vlgiitr.github.io/project/emoticon/</link>
      <pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/project/emoticon/</guid>
      <description>&lt;p&gt;This repository contains the code of our model submitted for the ICMI 2018 EmotiW Group-Level Emotion Recognition Challenge. The model was ranked 4th in the challenge. The paper proposes an end-to-end model for jointly learning the scene and facial features of an image for group-level emotion recognition.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Neural Turing Machines</title>
      <link>https://vlgiitr.github.io/project/ntm/</link>
      <pubDate>Wed, 26 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/project/ntm/</guid>
      <description>&lt;p&gt;This repository is a stable Pytorch implementation of a Neural Turing Machine and contains the code for training, evaluating and visualizing results for the Copy, Repeat Copy, Associative Recall and Priority Sort tasks. The code has been tested for all 4 tasks and the results obtained are in accordance with the results mentioned in the paper.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An Attention Model for Group Level Emotion Recognition</title>
      <link>https://vlgiitr.github.io/publication/att/</link>
      <pubDate>Thu, 02 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/publication/att/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dynamic Memory Network Plus</title>
      <link>https://vlgiitr.github.io/project/dmn_plus/</link>
      <pubDate>Fri, 08 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/project/dmn_plus/</guid>
      <description>&lt;p&gt;This is the Pytorch implementation of the paper Dynamic Memory Network for Visual and Textual Question Answering. This paper is an improved version of the original paper Ask Me Anything: Dynamic Memory Networks for Natural Language Processing. The major difference between these ideas is in the functioning of the input module and the memory module which has been explained in detail in the IPython notebook file of this repo.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://vlgiitr.github.io/recruitments/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recruitments/</guid>
      <description>&lt;p&gt;VLG goes recruiting for its core members and designers! For the recruitment process this year, we are introducing many ways to become a core team member at VLG. We encourage you to apply through as many ways as you wish.&lt;/p&gt;
&lt;h1 id=&#34;recruitment-test-for-1st-year&#34;&gt;Recruitment Test for 1st Year&lt;/h1&gt;
&lt;p&gt;Your familiarity with deep learning concepts will be tested along with a few open-ended questions to analyze your thinking and explaining skills.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Venue:&lt;/strong&gt; Room no - 004, APJ Block&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Time:&lt;/strong&gt; 9th March 7:00 pm to 8:30 pm&lt;/p&gt;
&lt;h1 id=&#34;pitch-your-project&#34;&gt;Pitch Your Project&lt;/h1&gt;
&lt;p&gt;Submit your ideas in the form of a well drafted proposal&lt;/p&gt;
&lt;!-- **Sample Project Proposal:** https://hackmd.io/wHJocycPS0O2V_u8olrNEQ --&gt;
&lt;p&gt;&lt;strong&gt;Proposal Submission Deadline:&lt;/strong&gt; 16th March 11:59pm&lt;/p&gt;
&lt;h1 id=&#34;call-for-bloggers&#34;&gt;Call For Bloggers&lt;/h1&gt;
&lt;p&gt;If you are a passionate writer and wish to share your knowledge and insights into the world of deep learning with our community, send us your articles. We&amp;rsquo;ll be publishing shortlisted ones through the Medium account of VLG.&lt;/p&gt;
&lt;!-- **General Tips And Instructions:** https://hackmd.io/bz1y1-E4TBeeCLu6AMfefQ --&gt;
&lt;p&gt;&lt;strong&gt;Blog submission deadline:&lt;/strong&gt; 16th March 11:59pm&lt;/p&gt;
&lt;h1 id=&#34;design-assignment&#34;&gt;Design Assignment:&lt;/h1&gt;
&lt;p&gt;We are also looking for designers to join our team. If you have a creative eye and love designing, we would love to hear from you.&lt;/p&gt;
&lt;!-- **Problem Statement:** https://www.notion.so/VLG-Design-Assignment-7637b17542874dfb8254a6e7960838e9  --&gt;
&lt;p&gt;&lt;strong&gt;Submission Deadline:&lt;/strong&gt; 17th March&lt;/p&gt;
&lt;p&gt;You can follow us on instagram and find posters for this year &lt;a href=&#34;https://www.instagram.com/p/Cpia28Ov6g_/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Archives</title>
      <link>https://vlgiitr.github.io/archives/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/archives/</guid>
      <description>&lt;hr&gt;
&lt;h2 id=&#34;open-projectshahahugoshortcode8s0hbhb&#34;&gt;&lt;a href=&#34;https://vlgiitr.github.io/open_projects/&#34;&gt;Open Projects&lt;/a&gt;&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Discussions</title>
      <link>https://vlgiitr.github.io/discussions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/discussions/</guid>
      <description>&lt;p&gt;Discussions for this semester will start by the end of September&#39;22. Meanwhile you can look into the previous discussions below.&lt;/p&gt;
&lt;h3 id=&#34;previous-semester-discussions&#34;&gt;Previous Semester Discussions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://vlgiitr.github.io/previous_discussions/spring_2022_discussion/&#34;&gt;Spring 2022 Discussions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://vlgiitr.github.io/previous_discussions/aut_2021_discussion/&#34;&gt;Autumn 2021 Discussions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://vlgiitr.github.io/previous_discussions/spring_2021_discussion/&#34;&gt;Spring 2021 Discussions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://vlgiitr.github.io/previous_discussions/aut_2020/&#34;&gt;Autumn 2020 Discussions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Open Projects</title>
      <link>https://vlgiitr.github.io/open_projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/open_projects/</guid>
      <description>&lt;p&gt;You have the four projects below to choose from and you can only pick one. Fill the &lt;a href=&#34;https://forms.gle/A64BMcAd6E2FTvEQ6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;form&lt;/a&gt; with your choice. Join our Open Slack Community or checkout our Instagram Post for more information.&lt;/p&gt;
&lt;p&gt;Form Deadline: 25th May EOD.&lt;/p&gt;
&lt;p&gt;Project Deadline: 22nd June 2023.&lt;/p&gt;
&lt;p&gt;The project will be verified based on your performance.&lt;/p&gt;
&lt;p&gt;Best Of Luck!&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;ai-generated-image-detection&#34;&gt;AI GENERATED IMAGE DETECTION&lt;/h2&gt;
&lt;p&gt;With the rise of generative AI, fake identities can be easily created using sophisticated algorithms. This has led to an increase in identity fraud, as fake identities can be used to gain access to online services and commit fraudulent activities. Thus, the purpose is to contribute to the development of more secure and reliable online services for everyone.&lt;/p&gt;
&lt;p&gt;Full project description: &lt;a href=&#34;https://hackmd.io/@UVZeWfL7Te-wnOqGGxH1kg/rJkZ_vQHn&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Here&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;multilingual-product-recommender-system&#34;&gt;MULTILINGUAL PRODUCT RECOMMENDER SYSTEM&lt;/h2&gt;
&lt;p&gt;Modelling customer shopping intentions is crucial for e-commerce stores, as it directly impacts user experience and engagement. With this intention, we aim to utilize the ‘Multilingual Shopping Session Dataset’, a dataset consisting of millions of user sessions from six different locales, where the major languages of products are English, German, Japanese, French, Italian, and Spanish.&lt;/p&gt;
&lt;p&gt;Full project description: &lt;a href=&#34;https://hackmd.io/@UVZeWfL7Te-wnOqGGxH1kg/B12Q1UXSn&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Here&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;stable-diffusion---image-to-prompt&#34;&gt;STABLE DIFFUSION - IMAGE TO PROMPT&lt;/h2&gt;
&lt;p&gt;The popularity of text-to-image models has spurned an entire new field of prompt engineering. Part art and part unsettled science, ML practitioners and researchers are rapidly grappling with understanding the relationships between prompts and the images they generate and in this project we aim to reverse the typical direction of a generative text-to-image model: instead of generating an image from a text prompt, can you create a model which can predict the text prompt given a generated image?&lt;/p&gt;
&lt;p&gt;Full project description: &lt;a href=&#34;https://hackmd.io/@SK-Singh/SJt2HYXB2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Here&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;image-matching---reconstruct-3d-scenes-from-2d&#34;&gt;IMAGE MATCHING - RECONSTRUCT 3D SCENES FROM 2D&lt;/h2&gt;
&lt;p&gt;Your best camera may just be the phone in your pocket. You might take a snap of a landmark, then share it with friends. By itself, that photo is two-dimensional and only includes the perspective of your shooting location. Of course, many people may have taken photos of that same landmark. If we were able to combine all of our photos, we may be able to create a more complete, three-dimensional view of any given thing and this is what we aim in this project.
Our objective is building a 3D model of a scene given an unstructured collection of images taken around it.&lt;/p&gt;
&lt;p&gt;Full project description: &lt;a href=&#34;https://hackmd.io/@SK-Singh/SJy18iXHh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Here&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;!-- &gt; Forms closed --&gt;
</description>
    </item>
    
    <item>
      <title>Sensorium 2022</title>
      <link>https://vlgiitr.github.io/project/sensorium/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/project/sensorium/</guid>
      <description>&lt;p&gt;The NeurIPS 2022 The SENSORIUM competition aimed to find the best neural predictive model that can predict the activity of thousands of neurons in the primary visual cortex of mice in response to natural images.&lt;/p&gt;
&lt;p&gt;In our submission for this competition, we attempted to improve the baseline model for the competition track- Sensorium+, where neural activity was to be predicted with given visual stimuli and other behavioural variables.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Team Members</title>
      <link>https://vlgiitr.github.io/team/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/team/</guid>
      <description></description>
    </item>
    
    <item>
      <title>VLG goes recruiting</title>
      <link>https://vlgiitr.github.io/recents/recruitments/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/recents/recruitments/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Weekend Talks with Researchers</title>
      <link>https://vlgiitr.github.io/dre/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vlgiitr.github.io/dre/</guid>
      <description>&lt;style&gt;
  .center {
  align-items: center;
  display: flex;
  justify-content: center;
  }
&lt;/style&gt;
&lt;div class=&#39;center&#39;&gt;
  &lt;iframe src=&#34;https://free.timeanddate.com/countdown/i7ukd1l7/n1863/cf100/cm0/cu4/ct0/cs0/ca0/co0/cr0/ss0/cac000/cpc000/pcfff/tc66c/fs225/szw320/szh135/iso2021-06-26T12:00:00&#34; allowtransparency=&#34;true&#34; frameborder=&#34;0&#34; width=&#34;320&#34; height=&#34;135&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;p&gt;&lt;strong&gt;Weekend Talks with researchers&lt;/strong&gt; is a two day event where researchers from different fields will share their work and experience. Join us on 26 June and 27 June 2021 for the event.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
